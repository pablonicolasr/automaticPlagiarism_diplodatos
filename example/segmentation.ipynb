{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import operator\n",
    "import functools\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.colors as mc\n",
    "import nltk\n",
    "import numpy as np\n",
    "import textstat\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "import textstat\n",
    "from lexicalrichness import LexicalRichness\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag, map_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    " # Feature Selection\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beda546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The screen is cleaned\n",
    "class ClearScreen():\n",
    "    \n",
    "    def __init__(self):\n",
    "    \n",
    "        self.clear = os.system('cls' if os.name=='nt' else 'clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFiles(path, extension=\"*.txt\"): \n",
    "    \n",
    "    # Construir el patrón de búsqueda\n",
    "    patron = os.path.join(path, extension)\n",
    "    \n",
    "    # Obtener la lista de archivos que coinciden con el patrón\n",
    "    archivos = glob.glob(patron)\n",
    "    \n",
    "    return len(archivos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54727b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation:\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        \n",
    "        self.text = text\n",
    "        \n",
    "    def sentSegmentation(self):\n",
    "        \n",
    "        return sent_tokenize(self.text)\n",
    "    \n",
    "    def paraSegmentation(self):\n",
    "        \n",
    "        texto = self.text.split(\"\\n\\n\")\n",
    "        \n",
    "        return list(filter(bool, texto))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(os.getcwd(), \"corpus\", \"suspicious-document00013.txt\"), encoding= \"utf-8-sig\")\n",
    "\n",
    "text = file.read()\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Seg = Segmentation(text)\n",
    "\n",
    "sentSeg = Seg.sentSegmentation()\n",
    "\n",
    "paraSeg = Seg.paraSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sentSeg))\n",
    "print(len(paraSeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentSeg):\n",
    "    print(f\"Oracion: {i} --> Texto: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241fa8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, paragraph in enumerate(paraSeg):\n",
    "    print(f\"Parrafo: {j} --> Texto: {paragraph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a169e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfleshReadingEase(text):\n",
    "    \n",
    "    fleshReadingEase = 0.0\n",
    "    \n",
    "    fleshReadingEase = textstat.flesch_reading_ease(text)\n",
    "    \n",
    "    return fleshReadingEase\n",
    "\n",
    "\n",
    "def gettypeToken(text):    \n",
    "    tam = len(text)\n",
    "    if tam <= 0:        \n",
    "        text = 0    \n",
    "    else:\n",
    "        try:\n",
    "            text = LexicalRichness(text)    \n",
    "            text = text.ttr\n",
    "        except ZeroDivisionError:\n",
    "            text = 0    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb5028",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = []\n",
    "\n",
    "for i, value in enumerate(sentSeg):\n",
    "    \n",
    "    datos.append([i, value, getfleshReadingEase(value), gettypeToken(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(datos, columns=[\"index\", \"text\", \"fleshReadingEase\", \"typeToken\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for j, value in enumerate(paragraph):\n",
    "    \n",
    "    data.append([i, value, getfleshReadingEase(value), gettypeToken(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c469208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data, columns=[\"index\", \"text\", \"fleshReadingEase\", \"typeToken\"])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29479f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
